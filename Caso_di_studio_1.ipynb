{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNhSifLMa5fvtWwWgDn1KHS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iacopoooo/Tesi/blob/main/Caso_di_studio_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UgjM1LDzMYew"
      },
      "outputs": [],
      "source": [
        "# ==============================================================\n",
        "# 1. Installazione librerie necessarie\n",
        "# (alcune sono già presenti in Colab, ma per sicurezza)\n",
        "# ==============================================================\n",
        "!pip install pandas numpy scikit-learn matplotlib seaborn\n",
        "\n",
        "# ==============================================================\n",
        "# 2. Import librerie\n",
        "# ==============================================================\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# ==============================================================\n",
        "# 3. Caricamento del dataset\n",
        "# ==============================================================\n",
        "# Devi caricare il file cicids2017.csv su Colab:\n",
        "# Colab → barra laterale sinistra → \"Files\" → \"Upload\" → scegli il CSV\n",
        "# oppure monta Google Drive:\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "# e poi usa il percorso giusto, es: '/content/drive/MyDrive/cicids2017.csv'\n",
        "\n",
        "try:\n",
        "    df_iter = pd.read_csv(\"cicids2017.csv\", iterator=True, chunksize=10000)\n",
        "    df = pd.concat([chunk.sample(frac=0.1, random_state=42) for chunk in df_iter])\n",
        "    print(\"Dataset caricato con successo.\")\n",
        "except FileNotFoundError:\n",
        "    print(\"Errore: 'cicids2017.csv' non trovato.\")\n",
        "    raise\n",
        "\n",
        "# Pulizia nomi colonne\n",
        "df.columns = (\n",
        "    df.columns.str.strip()\n",
        "    .str.lower()\n",
        "    .str.replace(\" \", \"_\")\n",
        "    .str.replace(\"[^a-zA-Z0-9_]\", \"\", regex=True)\n",
        ")\n",
        "\n",
        "print(f\"Shape dataset: {df.shape}\")\n",
        "df.head()\n",
        "\n",
        "# ==============================================================\n",
        "# 4. Preprocessing\n",
        "# ==============================================================\n",
        "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "if \"label\" not in df.columns:\n",
        "    raise KeyError(\"Colonna 'label' non trovata, controlla il dataset!\")\n",
        "\n",
        "X = df.drop(\"label\", axis=1)\n",
        "y = df[\"label\"]\n",
        "\n",
        "print(\"Distribuzione classi:\")\n",
        "print(y.value_counts())\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Split train/test\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_scaled, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "# ==============================================================\n",
        "# 5. Addestramento Random Forest\n",
        "# ==============================================================\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "y_pred = rf.predict(X_test)\n",
        "\n",
        "print(\"Accuracy RF:\", accuracy_score(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred, zero_division=0))\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "plt.title(\"Matrice di Confusione - Random Forest\")\n",
        "plt.show()\n",
        "\n",
        "# Importanza feature\n",
        "importances = pd.Series(rf.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
        "print(\"Top 10 feature importanti:\")\n",
        "print(importances.head(10))\n",
        "# ==============================================================\n",
        "# 6. Addestramento MLP\n",
        "# ==============================================================\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.exceptions import ConvergenceWarning\n",
        "import warnings\n",
        "\n",
        "mlp = MLPClassifier(\n",
        "    hidden_layer_sizes=(50, 25),\n",
        "    max_iter=300,\n",
        "    random_state=42,\n",
        "    early_stopping=True,\n",
        "    validation_fraction=0.1,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "with warnings.catch_warnings():\n",
        "    warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
        "    mlp.fit(X_train, y_train)\n",
        "\n",
        "y_pred_mlp = mlp.predict(X_test)\n",
        "\n",
        "print(\"Accuracy MLP:\", accuracy_score(y_test, y_pred_mlp))\n",
        "print(classification_report(y_test, y_pred_mlp, zero_division=0))\n",
        "\n",
        "cm_mlp = confusion_matrix(y_test, y_pred_mlp)\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.heatmap(cm_mlp, annot=True, fmt=\"d\", cmap=\"Greens\")\n",
        "plt.title(\"Matrice di Confusione - MLP\")\n",
        "plt.show()\n",
        "# ==============================================================\n",
        "# 7. Confronto metriche per classe\n",
        "# ==============================================================\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "class_labels = sorted(np.unique(y_test).astype(str))\n",
        "\n",
        "precision_rf, recall_rf, f1_rf, _ = precision_recall_fscore_support(y_test, y_pred, labels=np.unique(y_test), zero_division=0)\n",
        "precision_mlp, recall_mlp, f1_mlp, _ = precision_recall_fscore_support(y_test, y_pred_mlp, labels=np.unique(y_test), zero_division=0)\n",
        "\n",
        "x = np.arange(len(class_labels))\n",
        "width = 0.35\n",
        "\n",
        "fig, axs = plt.subplots(1, 3, figsize=(18, 6), sharey=True)\n",
        "\n",
        "axs[0].bar(x - width/2, precision_rf, width, label=\"RF\", color=\"orange\")\n",
        "axs[0].bar(x + width/2, precision_mlp, width, label=\"MLP\", color=\"red\")\n",
        "axs[0].set_title(\"Precision\")\n",
        "axs[0].set_xticks(x)\n",
        "axs[0].set_xticklabels(class_labels, rotation=45)\n",
        "\n",
        "axs[1].bar(x - width/2, recall_rf, width, label=\"RF\", color=\"orange\")\n",
        "axs[1].bar(x + width/2, recall_mlp, width, label=\"MLP\", color=\"red\")\n",
        "axs[1].set_title(\"Recall\")\n",
        "axs[1].set_xticks(x)\n",
        "axs[1].set_xticklabels(class_labels, rotation=45)\n",
        "\n",
        "axs[2].bar(x - width/2, f1_rf, width, label=\"RF\", color=\"orange\")\n",
        "axs[2].bar(x + width/2, f1_mlp, width, label=\"MLP\", color=\"red\")\n",
        "axs[2].set_title(\"F1-score\")\n",
        "axs[2].set_xticks(x)\n",
        "axs[2].set_xticklabels(class_labels, rotation=45)\n",
        "\n",
        "for ax in axs:\n",
        "    ax.set_ylim(0, 1.1)\n",
        "    ax.grid(True, axis=\"y\")\n",
        "\n",
        "axs[2].legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    }
  ]
}